{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation with an RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/unconventional-neural-networks/blob/master/text-generation/Text_Generation_with_an_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlXYTQSmKsdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, print_function, unicode_literals, absolute_import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfDV-_zRq1Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JauRNGVaz8kJ",
        "colab_type": "code",
        "outputId": "39daedf7-1def-4040-fc06-406a4ff28966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFckfKAYVt9A",
        "colab_type": "code",
        "outputId": "b136ed72-f5f0-4e75-b3ab-36d552920545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43IIQKzOVzj9",
        "colab_type": "code",
        "outputId": "3ea1af08-ab31-4797-d893-50661278d7ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print('{} unique characters.'.format(len(vocab)))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 unique characters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62J12YuBV9Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmukF-UTWrvl",
        "colab_type": "code",
        "outputId": "4655ddcc-16f0-4a9d-c8c5-20fcbb25f13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print(\"{\")\n",
        "for char, _ in zip(char2idx, range(20)):\n",
        "  print(' {:4s}: {:3d}, '.format(repr(char), char2idx[char]))\n",
        "print('   ...\\n')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            " '\\n':   0, \n",
            " ' ' :   1, \n",
            " '!' :   2, \n",
            " '$' :   3, \n",
            " '&' :   4, \n",
            " \"'\" :   5, \n",
            " ',' :   6, \n",
            " '-' :   7, \n",
            " '.' :   8, \n",
            " '3' :   9, \n",
            " ':' :  10, \n",
            " ';' :  11, \n",
            " '?' :  12, \n",
            " 'A' :  13, \n",
            " 'B' :  14, \n",
            " 'C' :  15, \n",
            " 'D' :  16, \n",
            " 'E' :  17, \n",
            " 'F' :  18, \n",
            " 'G' :  19, \n",
            "   ...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-LXjO_b_ESz",
        "colab_type": "code",
        "outputId": "e40d92e1-442a-4a1e-9775-42b5ecc1db2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'{repr(text[:15])} ------ characters mapped to int ------------> {text_as_int[:15]}')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\n' ------ characters mapped to int ------------> [18 47 56 57 58  1 15 47 58 47 64 43 52 10  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQFj9Vmo_USn",
        "colab_type": "text"
      },
      "source": [
        "### The prediction task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITCQD0wp_f1c",
        "colab_type": "text"
      },
      "source": [
        "Given a character, or a sequence of characters, what is the most probable next character? This is the task we're training the model to perform. The input to the model will be a sequence of characters, and we train the model to predict the outputâ€”the following character at each time step.\n",
        "\n",
        "Since RNNs maintain an internal state that depends on the previously seen elements, given all the characters computed until this moment, what is the next character?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt-0U_e5_jXE",
        "colab_type": "text"
      },
      "source": [
        "### Create training examples and targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcsPhghp_oLu",
        "colab_type": "text"
      },
      "source": [
        "Next divide the text into example sequences. Each input sequence will contain seq_length characters from the text.\n",
        "\n",
        "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
        "\n",
        "So break the text into chunks of seq_length+1. For example, say seq_length is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\".\n",
        "\n",
        "To do this first use the tf.data.Dataset.from_tensor_slices function to convert the text vector into a stream of character indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQfZbeLfAGZI",
        "colab_type": "code",
        "outputId": "eba1b348-74b6-4d7e-8cae-4899f92e97f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "seq_length = 100\n",
        "\n",
        "examples_per_epoch = len(text)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(10):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j04PcZqgAYkY",
        "colab_type": "code",
        "outputId": "08ce1831-306f-4bab-ae23-56278fd6bfbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(''.join(idx2char[item.numpy()]))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n",
            "now Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us ki\n",
            "ll him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be d\n",
            "one: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeXx-LmUAqYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXg8DkEuBEqP",
        "colab_type": "code",
        "outputId": "144e9a99-2920-4cd3-e69d-c5b47048db0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print('Target data: ',repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target data:  'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaqDTlWRBdzR",
        "colab_type": "code",
        "outputId": "fc62d4fa-b298-49f5-d65e-2c9c2a32e9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "  print(\"Step: {:4d}\".format(i))\n",
        "  print(\" input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "  print(\" target: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step:    0\n",
            " input: 18 ('F')\n",
            " target: 47 ('i')\n",
            "Step:    1\n",
            " input: 47 ('i')\n",
            " target: 56 ('r')\n",
            "Step:    2\n",
            " input: 56 ('r')\n",
            " target: 57 ('s')\n",
            "Step:    3\n",
            " input: 57 ('s')\n",
            " target: 58 ('t')\n",
            "Step:    4\n",
            " input: 58 ('t')\n",
            " target: 1 (' ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMGIMhFnCDr5",
        "colab_type": "code",
        "outputId": "9fff7b6a-c23f-40ef-df6c-6804e89c0adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset.element_spec"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KujPjQ1WHbcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KscWxsdHf6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "                               tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "                               tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "                              #  tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform')),\n",
        "                              #  tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform')),\n",
        "                               tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRGd58psIeGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ed4d88a-cce6-4702-aa6e-c83bbf90eda0"
      },
      "source": [
        "model = build_model(vocab_size=len(vocab), embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.backward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.backward_layer.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.backward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.backward_layer.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDP0NUPSIoBg",
        "colab_type": "code",
        "outputId": "f8cfeef3-1bbf-4e98-96da-38e0c10e3a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru_12 (GRU)                 (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "gru_13 (GRU)                 (64, None, 1024)          6297600   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 10,319,169\n",
            "Trainable params: 10,319,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGdTN1rhIqG0",
        "colab_type": "code",
        "outputId": "d8dc4431-4aff-439b-f35a-4121b10190d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# batch_size, sequence_length, vocab_size\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65) # batch_size, sequence_length, vocab_size\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PjS4sucJGWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npj-JSkfVaQb",
        "colab_type": "text"
      },
      "source": [
        "To get actual predictions from the model we need to sample from the output distribution, to get actual character indices. This distribution is defined by the logits over the character vocabulary.\n",
        "\n",
        "**Note: It is important to sample from this distribution as taking the argmax of the distribution can easily get the model stuck in a loop.**c\n",
        "\n",
        "Try it for the first example in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh3vQlGJUXRa",
        "colab_type": "code",
        "outputId": "aace75a3-9de2-4eb4-c4e3-e0bcc373b41c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print('Input: \\n', repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\",repr(\"\".join(idx2char[sampled_indices])))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'at an arm he has! he turned me about with his\\nfinger and his thumb, as one would set up a top.\\n\\nSeco'\n",
            "\n",
            "Next Char Predictions: \n",
            " \"v\\n?yS$;BUjzehEXJh.hwD-Dc!yHhUHIdkbCuNQ'TdoPbfxY,H;3gz?tXaPCu-Tp\\nBuXubQYPrzQ?ibCRNB;3!ZNewSrPz&cNKOo'\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4u_oM0AVEhJ",
        "colab_type": "code",
        "outputId": "cb585650-8937-4ceb-91f1-2a9a6a095876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Predictions shape: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Scalar loss: \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions shape:  (64, 100, 65) # (batch_size, sequence_length, vocab_size)\n",
            "Scalar loss:  4.1751485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3ryOgaCWnnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqYXaVi1XMx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mti4--7oXTE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXLZsclGXVfs",
        "colab_type": "code",
        "outputId": "fb4e9f21-6846-4cf1-f5f1-0afa5995f08b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 172 steps\n",
            "Epoch 1/30\n",
            "172/172 [==============================] - 20s 117ms/step - loss: 2.6019\n",
            "Epoch 2/30\n",
            "172/172 [==============================] - 18s 106ms/step - loss: 1.8205\n",
            "Epoch 3/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 1.5612\n",
            "Epoch 4/30\n",
            "172/172 [==============================] - 18s 104ms/step - loss: 1.4445\n",
            "Epoch 5/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 1.3746\n",
            "Epoch 6/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 1.3229\n",
            "Epoch 7/30\n",
            "172/172 [==============================] - 18s 106ms/step - loss: 1.2763\n",
            "Epoch 8/30\n",
            "172/172 [==============================] - 18s 106ms/step - loss: 1.2319\n",
            "Epoch 9/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 1.1865\n",
            "Epoch 10/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 1.1390\n",
            "Epoch 11/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 1.0859\n",
            "Epoch 12/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 1.0294\n",
            "Epoch 13/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.9684\n",
            "Epoch 14/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.9052\n",
            "Epoch 15/30\n",
            "172/172 [==============================] - 18s 106ms/step - loss: 0.8427\n",
            "Epoch 16/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.7826\n",
            "Epoch 17/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.7264\n",
            "Epoch 18/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.6754\n",
            "Epoch 19/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.6309\n",
            "Epoch 20/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.5901\n",
            "Epoch 21/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.5573\n",
            "Epoch 22/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.5296\n",
            "Epoch 23/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.5067\n",
            "Epoch 24/30\n",
            "172/172 [==============================] - 18s 106ms/step - loss: 0.4873\n",
            "Epoch 25/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.4700\n",
            "Epoch 26/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.4567\n",
            "Epoch 27/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.4439\n",
            "Epoch 28/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.4334\n",
            "Epoch 29/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.4257\n",
            "Epoch 30/30\n",
            "172/172 [==============================] - 18s 105ms/step - loss: 0.4180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_VG7FKHXc3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46de6b51-53c6-421a-c41b-86348999c256"
      },
      "source": [
        "# https://github.com/Skuldur/Classical-Piano-Composer\n",
        "\n",
        "tf.train.latest_checkpoint(checkpoint_dir=checkpoint_dir)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_30'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMD4PakLCe3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size=vocab_size, embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir=checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-PcdxWgC5dX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a31746e5-89ed-4052-f0b4-e703d9aeda67"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (1, None, 256)            16640     \n",
            "_________________________________________________________________\n",
            "gru_14 (GRU)                 (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "gru_15 (GRU)                 (1, None, 1024)           6297600   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (1, None, 65)             66625     \n",
            "=================================================================\n",
            "Total params: 10,319,169\n",
            "Trainable params: 10,319,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zq22ktRDCwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  num_generate = 10000\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "  temperature = 1.0\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_GZRXypbeOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eefe3120-1595-4dfc-d37e-a2966d675aa4"
      },
      "source": [
        "print(generate_text(model, start_string='ROMEO: '))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO: but you shall feel while a prison.\n",
            "\n",
            "PERCINIUS:\n",
            "You should account me not your stomach.\n",
            "Perchance subdress and crown in peace;\n",
            "Nor colour of a cruel father's he!\n",
            "Now, by the jealous and she was with me in heaven.\n",
            "Hark! when fair son walk'd, Juliet, give me!\n",
            "\n",
            "First Wate to France\n",
            "And cloister eer through an act worship's head.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Peace be which heaven with lawful man world's enemies,\n",
            "Of all the unshoulder for a looker sorious down.\n",
            "\n",
            "MONTAGUE:\n",
            "Brother, Tell him, and slaughter me and my good friends;\n",
            "And, as I guess, and give way here: God will be done:\n",
            "Prepare here not: why, then the conserves you\n",
            "have punks' advantage in them and could see a coal-blaze\n",
            "of brother's woman, if they never\n",
            "Marry uncontroll'd the fairest I, lord,\n",
            "To make her gown. How save your son--\n",
            "\n",
            "BRAKENBURY:\n",
            "What was my buried?\n",
            "Our holy let me think.\n",
            "\n",
            "BENONIO:\n",
            "Of all my weapon drown!\n",
            "\n",
            "BENVOLIO:\n",
            "Two thou art good of the harm,\n",
            "Will make thee that the traitor's head,\n",
            "Save bound our old acquaintant of the earth,\n",
            "Or my divine soul and young R may disman to my mind.\n",
            "\n",
            "MIRANDA:\n",
            "Sir, do you hear, sir? have you married\n",
            "By underhand corrupted foul gentleman;\n",
            "Nor never only confessor, let them have I lie.\n",
            "\n",
            "SAMPSON:\n",
            "\n",
            "GREGORY:\n",
            "No.\n",
            "\n",
            "SAMPSON:\n",
            "No. Signior Vincentio.\n",
            "\n",
            "VIRINENIUS:\n",
            "And most accursed am I\n",
            "To bear a poison, I would to hence in others: and\n",
            "further will not cross'd; and what hath brought you to,\n",
            "I'll have no Cutizens:\n",
            "We can: my royal liege,\n",
            "Yea, that she is a point. of but my unrectorn.\n",
            "\n",
            "KING HENRY VI put better to stand.\n",
            "This is thy hand; 'tis weary bark.\n",
            "\n",
            "MENENIUS:\n",
            "Sir, I shall tell you. With a kinsman,\n",
            "Cry whee standing on; from him;\n",
            "Made him a slave?\n",
            "My brother slew my master to\n",
            "him: we are undone! ah, what comes we have come.\n",
            "Some aqua vitae, mark me. that the begin to plead for him.\n",
            "My lord, he fears me now to strange him.\n",
            "You may not hear him here again. Go with him, provost!\n",
            "\n",
            "ISABELLA:\n",
            "O gracious daughter.\n",
            "What if a man that keeps that outward fam.\n",
            "\n",
            "SICINIUS:\n",
            "The aus I have done so, for smile,\n",
            "And not a man which now comes one: a gentleman and a\n",
            "dangerous courtesy.\n",
            "\n",
            "Second Murderer:\n",
            "Let's to the Richard, thou wert'st,\n",
            "To cro came from Buckingham.\n",
            "Upon his party: he, mistrusting them were with me unto the trust of Richlo.\n",
            "And the rays to weeping of her tears, and I'll render him;\n",
            "And give me leave to shake my men,\n",
            "And then derived at wilt than can ear\n",
            "The body of the death of hearts\n",
            "Which is the wish: send him, my horse.\n",
            "\n",
            "GRUMIO:\n",
            "Call the contunes of them! ENIUThey say one.\n",
            "\n",
            "AUFIDIUS:\n",
            "Where words you have contented festival,\n",
            "Turnets against the house of York suppose\n",
            "SIRINIUS:\n",
            "Weprebs mine own and loss\n",
            "and king is held\n",
            "Untimely storms may know thou canst, I will not trumpet.\n",
            "But can we minister cordial and nature\n",
            "TIO:\n",
            "A craw to cry, Come on; I beseech you,\n",
            "I may enter till my death\n",
            "Tio; I am now at pray and tear;\n",
            "And so he was never born death more comet in having her.\n",
            "Promost humble, march:\n",
            "True Coptain of great enemy.\n",
            "Cannt so grieve, to approve sens;\n",
            "And, if you will, in falling, round about the city.\n",
            "Where art thou do proffered, the king must hear, for it\n",
            "seemed so penitent, and others.\n",
            "\n",
            "CORIOLANUS:\n",
            "So then we shall have a sight of marriage of unsking-she:\n",
            "Ah, and further with her blood lodger hope:\n",
            "Thanks, gentlemen, you shall he could not keep; which I may never have made thy words\n",
            "Of this sir-reverence log?\n",
            "\n",
            "CLAUDIO:\n",
            "Dr modest preterms in prison.\n",
            "\n",
            "KING RICHARD III:\n",
            "Have not too heard the time between's the welf man so below,\n",
            "A thanking on't.\n",
            "\n",
            "ANTONIO:\n",
            "True; or thee? how soundly dry.\n",
            "3 KING HENRY VI\n",
            "\n",
            "KING EDWARD IV:\n",
            "What doth beasts, as thou art stame,\n",
            "Which ne'er can make a mutiny of horses!\n",
            "\n",
            "KATHARINA:\n",
            "What, in gracious lord, excuse them all;\n",
            "You understake ds:\n",
            "A:\n",
            "Young Henry Pimpernel both, and have\n",
            "A vessel rides fast beautyful king.\n",
            "\n",
            "Lord:\n",
            "Thou art a fool, will turn you at a blow,\n",
            "An honourable fathers mother; for I must\n",
            "Confess your grace, which never bear\n",
            "A July's dear blood should be revenged for that.\n",
            "\n",
            "BIANCA:\n",
            "I must now too.\n",
            "What, are you? nger! his face\n",
            "As easy but to throne; and reason, for let Time,\n",
            "Sir John Dissension of a mover hours and the name!\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "It is no orday thender service\n",
            "Times not this will fly.\n",
            "Bare you quarrel, sir. Frame you to give him again.\n",
            "\n",
            "Clown:\n",
            "Thou wilt ame old and reconcile\n",
            "To Rome of our swords deal upon:\n",
            "To visat I will advertice,\n",
            "Yet all the world, the foe do visit the chafty bodzed burns\n",
            "Her chancel of my supper beauty off from all post:\n",
            "How should have ta'en no father of a dream, are an hair\n",
            "To enter our command.\n",
            "\n",
            "ANTIGONUS:\n",
            "Ay, ay, a fortune lives; my heartion.\n",
            "I conjured me;\n",
            "And in my wanderous stoild have known the root:\n",
            "Sometimes you would deliver it well in our return.\n",
            "Women are unpropheted to me.\n",
            "Then wherefore do not know our fortune,\n",
            "And tutor's name would live.\n",
            "\n",
            "PETRUCHIO:\n",
            "O, to be crowned unto his bed;\n",
            "And be my word that made my speech conform'd the earth,\n",
            "To keep the prize envious fl she doth mook for:\n",
            "'Tis power, they are rich, but of all towns and cities forswear'd,\n",
            "That thou, Plaughter and my joy,\n",
            "Did not a resemblancent,\n",
            "Not how to curse. I know their love provides\n",
            "I now no lesser than thy land\n",
            "Wherein thyself shalt accompany you as his soldiers;\n",
            "If you do so, I spy convey well deserves it;\n",
            "He leck me say it was which changed me\n",
            "And therein neglige thee well! what he hath woo'?\n",
            "\n",
            "PERDITA:\n",
            "One of these is faltest delicate\n",
            "to death, and for that offer to beat my servant?\n",
            "\n",
            "VINCENTIO:\n",
            "Against all sense you do importune him; he cannot--the great danger\n",
            "Which this man's wife and victory.\n",
            "3 KING HENRY VI\n",
            "\n",
            "KING EDWARD IV:\n",
            "It were no deeper wounds? O, where is Warwick?\n",
            "This drively only my heart abhors\n",
            "To better purpose married to the good Camillo,\n",
            "Whether I have seen and confessor,\n",
            "Divine him, madam, no; I must fall ng life out.\n",
            "\n",
            "TYBALT:\n",
            "For which you want were heavens in fear, Threws of noble prince,\n",
            "Lespersious lambssing on't.\n",
            "\n",
            "CAMILLO:\n",
            "Then there, thou worthio.\n",
            "\n",
            "PETRUCHIO:\n",
            "Nay, I think, you'll find\n",
            "The y the fair soul that case\n",
            "Is this your counsels, but our noble lordship\n",
            "Than death commandme minece.\n",
            "And this same needy man, whom favourable husband, I beseech thee!\n",
            "The man I can imaginning in the street,\n",
            "On Warwick, now he doth deny, I will not all oclament,\n",
            "Whip you of greatness: he\n",
            "sings yet may catch them at this fray.\n",
            "\n",
            "BENVOLIO:\n",
            "O, no! thou damest here you command:\n",
            "So cunning Licio, that he would owe\n",
            "His curses that have been concluded.\n",
            "\n",
            "RIVERS:\n",
            "A very borre uncle GYEY:\n",
            "And go fortwhat be ill, sir, I think,\n",
            "Which then will speak, the troubleous fantastic s.\n",
            "\n",
            "DUCHESS:\n",
            "Fear not, man: hear nothing here;\n",
            "bring forth the proofs for you would live with all which will I keep the very book:\n",
            "The word is curked me?\n",
            "No; strengthe and starks of her more competted to cheque,\n",
            "Unless and all the value of thy whom I\n",
            "The rest: where you but faults,\n",
            "And must else be ours.\n",
            "\n",
            "First Watchman:\n",
            "Whom should have the leisure s a clothes of tune to vent.\n",
            "\n",
            "YORK:\n",
            "Manageme as this, if things, glory-like,\n",
            "To the deep, he would not lose thee answer.\n",
            "Love each other to refuse his forces\n",
            "Or many an oline.\n",
            "Resoluted. The good gods,\n",
            "In self-moracomp and could not spell.\n",
            "But come, young waverer, sir, with such deeds doth make my vexity loves.\n",
            "\n",
            "GREMIO:\n",
            "While let us living heads?\n",
            "\n",
            "PROSPERO:\n",
            "By Pembroke of Surrey, paid you: but\n",
            "I could be content to give him come.\n",
            "\n",
            "ARIEL:\n",
            "Ay, master. Then, to be gone, besides, for Lancaster!\n",
            "Down with the dear'st so tender love and brothers,\n",
            "And witch sworas of thy tears and her no more behind\n",
            "But starve was for Claudio's death.\n",
            "Where's Cotus? my master calls\n",
            "for me and my deep and castles yielding to your\n",
            "resolution of it do I see them to your house;\n",
            "For God's sake, lords, give signal to the fight.\n",
            "\n",
            "WARWICK:\n",
            "Planted, he go along with the deep;\n",
            "Hold, there it is in what you promised York.\n",
            "\n",
            "KING HENRY VI:\n",
            "An if he mark me.\n",
            "\n",
            "Nurse:\n",
            "I know it, I:\n",
            "It is so, sir:\n",
            "I hope this reason studyeed he sly names,\n",
            "Like to his father's goodly charged,\n",
            "To give the hope to so green all o'er,\n",
            "And then full time every noble ord,\n",
            "Is coming now incopeit of that hangmy;\n",
            "I'll give my jewely for the tenth, and have found succession.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "There is our pinch, and let the marks plain we let them be,\n",
            "If you, Hortensio, thou bethat hours runs his goodness;\n",
            "And in her most vile parts of that for Henry's heart:\n",
            "Then, do not say King Richard in her most vile and ready, and I swear\n",
            "JUUENCE:\n",
            "Tell them to get their chairs;\n",
            "And in my heart thine image:\n",
            "The manner of your blessed love, she is\n",
            "The water and trade the stouthe steed\n",
            "Where he is, for itself nger less?\n",
            "Where makes hore As she shall ate.\n",
            "Had he been slay the rest were so,\n",
            "Let them have stood unto my study,\n",
            "To cross my outward course of tenderness\n",
            "If not, Isabel,\n",
            "Think with thy sceptre is outrage in this royal tree hath left us royal fruit;\n",
            "Which often hath no more sons of my trade:\n",
            "And there in honour and the heart of man;\n",
            "Where she at like a strange debt, nor daughter?\n",
            "The ngea-s I of it now.\n",
            "My Lord of Norfolk,--\n",
            "\n",
            "NORFOLK:\n",
            "A greater goodly trial before I can;\n",
            "And he shall sing his head to fight again.\n",
            "\n",
            "CLAUDIO:\n",
            "I think he would\n",
            "When first if he were well: but charge me, as it is,\n",
            "You shall have me and me, and no less too:\n",
            "This attorneys to the garns dead;\n",
            "There art thou happy: Tybalt would kill thee,\n",
            "By heaven, I hear the best\n",
            "In beauty was thy pew-bold in zeal on thee\n",
            "se:\n",
            "South out three-month be in spectacles?\n",
            "And who attend me? then to Bohemia?\n",
            "\n",
            "GLOUCESTER:\n",
            "Why that same news is move what thou art, for the ellardinal.\n",
            "Wherein?\n",
            "I'll to the king made from his child's love: I think\n",
            "Upon the joys of tain it at the season\n",
            "Are our commission;\n",
            "Yond creepings him and rap me her for me.\n",
            "\n",
            "Post:\n",
            "Alas post\n",
            "hotovested which they have strong are the French taken'd you?\n",
            "\n",
            "BUCKINGHAM:\n",
            "Well, our best deserved this sword,\n",
            "And give itself me: y, go to!\n",
            "O pray the gods, but let your renow in thee!\n",
            "Sedvant get her brother, here where is my lord against Henry that wide opposers: he\n",
            "sent the heirs of their friends: marry, then unto\n",
            "O that you c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiD4dJJccNR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}